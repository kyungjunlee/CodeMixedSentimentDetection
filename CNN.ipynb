{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(0)\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To get an ID of an available GPU\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import subprocess as sp\n",
    "\n",
    "ACCEPTABLE_AVAILABLE_MEMORY = 11167\n",
    "\n",
    "# https://github.com/yselivonchyk/TensorFlow_DCIGN/blob/master/utils.py\n",
    "def _output_to_list(output):\n",
    "  return output.decode('ascii').split('\\n')[:-1]\n",
    "\n",
    "\n",
    "def get_idle_gpu(leave_unmasked=1, random=True):\n",
    "  try:\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = _output_to_list(sp.check_output(command.split()))[1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    available_gpus = [i for i, x in enumerate(memory_free_values) if x > ACCEPTABLE_AVAILABLE_MEMORY]\n",
    "\n",
    "    if len(available_gpus) <= leave_unmasked:\n",
    "      print('Found only %d usable GPUs in the system' % len(available_gpus))\n",
    "      return -1\n",
    "\n",
    "    if random:\n",
    "      available_gpus = np.asarray(available_gpus)\n",
    "      np.random.shuffle(available_gpus)\n",
    "\n",
    "    gpu_to_use = available_gpus[0]\n",
    "    print(\"Using GPU: \", gpu_to_use)\n",
    "    \n",
    "    return int(gpu_to_use)\n",
    "    \"\"\"\n",
    "    # update CUDA variable\n",
    "    gpus = available_gpus[:leave_unmasked]\n",
    "    setting = ','.join(map(str, gpus))\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = setting\n",
    "    print('Left next %d GPU(s) unmasked: [%s] (from %s available)'\n",
    "          % (leave_unmasked, setting, str(available_gpus)))\n",
    "    \"\"\"\n",
    "  except FileNotFoundError as e:\n",
    "    print('\"nvidia-smi\" is probably not installed. GPUs are not masked')\n",
    "    print(e)\n",
    "    return -1\n",
    "  except sp.CalledProcessError as e:\n",
    "    print(\"Error on GPU masking:\\n\", e.output)\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:  4\n",
      "cuda:4\n"
     ]
    }
   ],
   "source": [
    "filename = 'data/train_conll_spanglish.csv'\n",
    "if torch.cuda.is_available():\n",
    "    gpu_id = \"cuda:{}\".format(get_idle_gpu(leave_unmasked=0))\n",
    "\n",
    "device = torch.device(gpu_id if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "import torchtext\n",
    "\n",
    "def label2int(label):\n",
    "    if label=='positive':\n",
    "        return 1\n",
    "    elif label=='negative':\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def label2float(label):\n",
    "    if label=='positive':\n",
    "        return 1.\n",
    "    elif label=='negative':\n",
    "        return 0.\n",
    "    else:\n",
    "        return 2.\n",
    "\n",
    "text_field = torchtext.data.Field(sequential=True,      # text sequence\n",
    "                                  tokenize=lambda x: x, # because are building a character-RNN\n",
    "                                  include_lengths=True, # to track the length of sequences, for batching\n",
    "                                  batch_first=True,\n",
    "                                  use_vocab=True)       # to turn each character into an integer index\n",
    "label_field = torchtext.data.Field(sequential=False,    # not a sequence\n",
    "                                   use_vocab=False,     # don't need to track vocabulary\n",
    "                                   is_target=True,\n",
    "                                   batch_first=True,\n",
    "                                   preprocessing=lambda x: label2int(x)) # convert text to 0 and 1\n",
    "\n",
    "fields = [('id', None),('text', text_field), ('label', label_field)]\n",
    "dataset = torchtext.data.TabularDataset(filename, # name of the file\n",
    "                                        \"tsv\",               # fields are separated by a tab\n",
    "                                        fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So that means tomorrow cruda segura lol --- 1\n",
      "Tonight peda segura --- 2\n",
      "Eres tan mala vieja bruja interesada#jamming --- 0\n",
      "Yo kiero Pretzels lol --- 2\n",
      "Fuck that ni ke el me vaya a mantener toda la vida lol --- 0\n",
      "I always tell my dad ke me kiero kasar con una vieja rika and me regaÃ±a telling me ke no sea interesada ha --- 0\n",
      "Ke me compre un carrito pa irme con mis friends and party lol --- 2\n",
      "Why can I just find a rich bitch ke me mantenga y ya ha --- 2\n",
      "Since I started working ya ni disfruto la vida lol --- 0\n",
      "My dad me regano cuzs I was telling that to my brother and lo andaba molestando lol --- 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(dataset[i].text, \"---\", dataset[i].label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = dataset.split(split_ratio=[0.8,0.1,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.build_vocab(dataset)\n",
    "# text_field.vocab.stoi\n",
    "# text_field.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.data.field.Field object at 0x7fafb434abe0>\n"
     ]
    }
   ],
   "source": [
    "len(text_field.vocab)\n",
    "print(label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = torchtext.data.BucketIterator(train,\n",
    "                                           batch_size=32,\n",
    "                                           sort_key=lambda x: len(x.text), # to minimize padding\n",
    "                                           sort_within_batch=True,        # sort within each batch\n",
    "                                           repeat=False, # repeat the iterator for multiple epochs\n",
    "                                           device=device)\n",
    "val_iter = torchtext.data.BucketIterator(val,\n",
    "                                         batch_size=32,\n",
    "                                         sort_key=lambda x: len(x.text), # to minimize padding\n",
    "                                         sort_within_batch=True,        # sort within each batch\n",
    "                                         repeat=False, # repeat the iterator for multiple epochs\n",
    "                                         device=device)\n",
    "test_iter = torchtext.data.BucketIterator(test,\n",
    "                                          batch_size=32,\n",
    "                                          sort_key=lambda x: len(x.text), # to minimize padding\n",
    "                                          sort_within_batch=True,        # sort within each batch\n",
    "                                          repeat=False, # repeat the iterator for multiple epochs\n",
    "                                          device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i, batch in enumerate(train_iter):\\n    if i >= 2:\\n        break\\n    print(batch.text)\\n#     print(batch.text[0].shape)\\n    print(batch.label)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i, batch in enumerate(train_iter):\n",
    "    if i >= 2:\n",
    "        break\n",
    "    print(batch.text)\n",
    "#     print(batch.text[0].shape)\n",
    "    print(batch.label)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport sklearn\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.naive_bayes import MultinomialNB\\nfrom sklearn.svm import SVC\\nimport os\\n\\nINPUT_PATH = \"data/train_conll_spanglish.csv\"\\nMAX_TWEET = 280\\n\\nchar_to_ind = {}\\nind_to_char = {}\\n\\nchar_to_ind.update({\"UNK\":0})\\nind_to_char.update({0:\"UNK\"})\\n\\ncount = 1\\n\\nwith open(INPUT_PATH, \\'r\\') as f:\\n    for line in f:\\n        for char in line.split(\\'\\t\\')[1]:\\n            if char.lower() not in char_to_ind:\\n                char_to_ind.update({char.lower():count})\\n                ind_to_char.update({count:char.lower()})\\n                count += 1\\n\\n#print(char_to_ind)\\n#print(ind_to_char)\\n\\nn_letters = len(char_to_ind)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Another version of preprocessing data\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "\n",
    "INPUT_PATH = \"data/train_conll_spanglish.csv\"\n",
    "MAX_TWEET = 280\n",
    "\n",
    "char_to_ind = {}\n",
    "ind_to_char = {}\n",
    "\n",
    "char_to_ind.update({\"UNK\":0})\n",
    "ind_to_char.update({0:\"UNK\"})\n",
    "\n",
    "count = 1\n",
    "\n",
    "with open(INPUT_PATH, 'r') as f:\n",
    "    for line in f:\n",
    "        for char in line.split('\\t')[1]:\n",
    "            if char.lower() not in char_to_ind:\n",
    "                char_to_ind.update({char.lower():count})\n",
    "                ind_to_char.update({count:char.lower()})\n",
    "                count += 1\n",
    "\n",
    "#print(char_to_ind)\n",
    "#print(ind_to_char)\n",
    "\n",
    "n_letters = len(char_to_ind)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef letterToTensor(letter, n_letters):\\n    tensor = torch.zeros(1, n_letters)\\n    tensor[0][char_to_ind[letter]] = 1\\n    return tensor\\n\\ndef lineToTensor(line, n_letters):\\n    tensor = torch.zeros(len(line), n_letters)\\n    for li, letter in enumerate(line):\\n        tensor[li][char_to_ind[letter]] = 1\\n    return tensor\\n\\ndef batchToTensor(batch, n_letters):\\n    tensor = torch.zeros(len(batch),MAX_TWEET,n_letters)\\n    for sentence, line in enumerate(batch):\\n        for li, letter in enumerate(line):\\n            tensor[sentence][li][char_to_ind[letter.lower()]] = 1\\n    return tensor\\n\\n\\n#print(letterToTensor('o'))\\nprint(lineToTensor('hello how are tou', n_letters).shape)\\nprint(batchToTensor(['hello friend', 'linear svm is better'], n_letters))\\nprint(batchToTensor(['hello friend', 'linear svm is better'], n_letters).shape)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def letterToTensor(letter, n_letters):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][char_to_ind[letter]] = 1\n",
    "    return tensor\n",
    "\n",
    "def lineToTensor(line, n_letters):\n",
    "    tensor = torch.zeros(len(line), n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][char_to_ind[letter]] = 1\n",
    "    return tensor\n",
    "\n",
    "def batchToTensor(batch, n_letters):\n",
    "    tensor = torch.zeros(len(batch),MAX_TWEET,n_letters)\n",
    "    for sentence, line in enumerate(batch):\n",
    "        for li, letter in enumerate(line):\n",
    "            tensor[sentence][li][char_to_ind[letter.lower()]] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "#print(letterToTensor('o'))\n",
    "print(lineToTensor('hello how are tou', n_letters).shape)\n",
    "print(batchToTensor(['hello friend', 'linear svm is better'], n_letters))\n",
    "print(batchToTensor(['hello friend', 'linear svm is better'], n_letters).shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrainpath = INPUT_PATH\\ntrain = pd.read_csv(trainpath, sep=\\'\\\\t\\', names=[\"ID\",\"SENTENCE\",\"LABEL\"])\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "trainpath = INPUT_PATH\n",
    "train = pd.read_csv(trainpath, sep='\\\\t', names=[\"ID\",\"SENTENCE\",\"LABEL\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(train['SENTENCE'][0].lower())\\ntrain_char_features = batchToTensor(train['SENTENCE'], n_letters)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(train['SENTENCE'][0].lower())\n",
    "train_char_features = batchToTensor(train['SENTENCE'], n_letters)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(train_char_features.shape)\\nfor in_tensor in train_char_features:\\n    print(in_tensor.shape)\\n    break\\n# train_char_features[0].shape\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(train_char_features.shape)\n",
    "for in_tensor in train_char_features:\n",
    "    print(in_tensor.shape)\n",
    "    break\n",
    "# train_char_features[0].shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    TextCNN implementation based on\n",
    "    https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        # one-hot vector, https://discuss.pytorch.org/t/convert-int-into-one-hot-format/507/11\n",
    "        self.embedding.weight.data = torch.eye(vocab_size)\n",
    "        # make embedding untrainable\n",
    "        self.embedding.weight.requires_grad=False\n",
    "        # first convolutional layer (three layers)\n",
    "        self.conv_0 = nn.ModuleList([\n",
    "                nn.Conv2d(in_channels = 1,\n",
    "                          out_channels = n_filters,\n",
    "                          kernel_size = (fs, embed_dim))\n",
    "                for fs in filter_sizes\n",
    "        ])\n",
    "        \"\"\"\n",
    "        self.conv_1 = nn.ModuleList([\n",
    "                nn.Conv2d(in_channels = n_filters,\n",
    "                          out_channels = n_filters,\n",
    "                          kernel_size = (fs, )\n",
    "                for fs in filter_sizes)\n",
    "        ])\n",
    "        \"\"\"\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        # text = (tensor of input, tensor of input length)\n",
    "#         print(text[0].shape)\n",
    "        # convert input to embeddings\n",
    "        in_data = text[0]\n",
    "        # in_data = [batch_size, sentence_length]\n",
    "        embedded = self.embedding(in_data)\n",
    "#         print(embedded)\n",
    "        # embedded = [batch_size, sentence_length, embedding_dimension]\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        # embedded = [batch_size, 1, sentence_length, embedding_dimension]\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.conv_0]\n",
    "        # conved_n = [batch_size, n_filters, sentence_length - filter_size[n] - 1]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        # pooled_n = [batch_size, n_filters]\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "        # cat = [batch_size, n_filters * len(filter_sizes)]\n",
    "        logit = self.fc(cat)\n",
    "        \n",
    "        return logit\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_char_features = [num_of_tweets, max. length of each tweet, embedding_size]\n",
    "\"\"\"\n",
    "num_features = list(train_char_features.shape)\n",
    "print(num_features)\n",
    "max_tweet_length = num_features[1]\n",
    "embedding_dim = num_features[2] # vocab_size\n",
    "\"\"\"\n",
    "input_dim = embedding_dim = len(text_field.vocab)\n",
    "n_filters = 3 # number of filters\n",
    "filter_sizes = [3, 4, 5] # like character 3-gram, 4-gram, 5-gram\n",
    "output_dim = 3\n",
    "dropout = 0.5\n",
    "\n",
    "model = TextCNN(input_dim, embedding_dim, n_filters, filter_sizes, output_dim, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 21243 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# checking the parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('The model has {} trainable parameters'.format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(logits, labels):\n",
    "    correct, total = 0, 0\n",
    "    _, predicted = torch.max(logits, 1)\n",
    "#     print(predicted, labels)\n",
    "#     print(predicted.shape, labels.shape)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "#         print(predictions, predictions.shape)\n",
    "#         print(batch.label, batch.label.shape)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = get_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc\n",
    "        \"\"\"\n",
    "        if i % 10 == 0:\n",
    "            print(\"batch: {}, loss: {}, acc: {}\".format(i, loss, acc*100))\n",
    "        \"\"\"\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = get_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.040683108329773 | Train Acc: 50.06666666666667%\n",
      "\tVal. Loss: 1.0351322128417644 |  Val. Acc: 49.79103343465046%\n",
      "Epoch: 2 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.0294901084899903 | Train Acc: 50.06666666666667%\n",
      "\tVal. Loss: 1.0244757216027442 |  Val. Acc: 49.80053191489361%\n",
      "Epoch: 3 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.0223534803390504 | Train Acc: 50.06666666666667%\n",
      "\tVal. Loss: 1.0171105316344728 |  Val. Acc: 49.81003039513678%\n",
      "Epoch: 4 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.0168536806106567 | Train Acc: 50.06666666666667%\n",
      "\tVal. Loss: 1.0123594631540014 |  Val. Acc: 49.80053191489361%\n",
      "Epoch: 5 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.014168970743815 | Train Acc: 50.06666666666667%\n",
      "\tVal. Loss: 1.009469671452299 |  Val. Acc: 49.7815349544073%\n",
      "Epoch: 6 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.0102888975143434 | Train Acc: 50.06666666666667%\n",
      "\tVal. Loss: 1.007010245576818 |  Val. Acc: 49.81003039513678%\n",
      "Epoch: 7 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.0089961358706157 | Train Acc: 50.06666666666667%\n",
      "\tVal. Loss: 1.0053887811112912 |  Val. Acc: 49.81003039513678%\n",
      "Epoch: 8 | Epoch Time: 0m 2s\n",
      "\tTrain Loss: 1.0064233090082804 | Train Acc: 50.06666666666667%\n",
      "\tVal. Loss: 1.0039161456392167 |  Val. Acc: 49.79103343465046%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
    "    \n",
    "    print('Epoch: {} | Epoch Time: {}m {}s'.format(epoch+1, epoch_mins, epoch_secs))\n",
    "    print('\\tTrain Loss: {} | Train Acc: {}%'.format(train_loss, train_acc*100))\n",
    "    print('\\tVal. Loss: {} |  Val. Acc: {}%'.format(valid_loss, valid_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
