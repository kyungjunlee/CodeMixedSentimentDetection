{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(0)\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/train_conll_spanglish.csv'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import torchtext\n",
    "\n",
    "def label2int(label):\n",
    "    if label=='positive':\n",
    "        return 1\n",
    "    elif label=='negative':\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def label2float(label):\n",
    "    if label=='positive':\n",
    "        return 1.\n",
    "    elif label=='negative':\n",
    "        return 0.\n",
    "    else:\n",
    "        return 2.\n",
    "\n",
    "text_field = torchtext.data.Field(sequential=True,      # text sequence\n",
    "                                  tokenize=lambda x: x, # because are building a character-RNN\n",
    "                                  include_lengths=True, # to track the length of sequences, for batching\n",
    "                                  batch_first=True,\n",
    "                                  use_vocab=True)       # to turn each character into an integer index\n",
    "label_field = torchtext.data.Field(sequential=False,    # not a sequence\n",
    "                                   use_vocab=False,     # don't need to track vocabulary\n",
    "                                   is_target=True,\n",
    "                                   batch_first=True,\n",
    "                                   preprocessing=lambda x: label2int(x)) # convert text to 0 and 1\n",
    "\n",
    "fields = [('id', None),('text', text_field), ('label', label_field)]\n",
    "dataset = torchtext.data.TabularDataset(filename, # name of the file\n",
    "                                        \"tsv\",               # fields are separated by a tab\n",
    "                                        fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So that means tomorrow cruda segura lol --- 1\n",
      "Tonight peda segura --- 2\n",
      "Eres tan mala vieja bruja interesada#jamming --- 0\n",
      "Yo kiero Pretzels lol --- 2\n",
      "Fuck that ni ke el me vaya a mantener toda la vida lol --- 0\n",
      "I always tell my dad ke me kiero kasar con una vieja rika and me rega√±a telling me ke no sea interesada ha --- 0\n",
      "Ke me compre un carrito pa irme con mis friends and party lol --- 2\n",
      "Why can I just find a rich bitch ke me mantenga y ya ha --- 2\n",
      "Since I started working ya ni disfruto la vida lol --- 0\n",
      "My dad me regano cuzs I was telling that to my brother and lo andaba molestando lol --- 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(dataset[i].text, \"---\", dataset[i].label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = dataset.split(split_ratio=[0.8,0.1,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.build_vocab(dataset)\n",
    "# text_field.vocab.stoi\n",
    "# text_field.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torchtext.data.field.Field object at 0x3645c55c0>\n"
     ]
    }
   ],
   "source": [
    "len(text_field.vocab)\n",
    "print(label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = torchtext.data.BucketIterator(train,\n",
    "                                           batch_size=32,\n",
    "                                           sort_key=lambda x: len(x.text), # to minimize padding\n",
    "                                           sort_within_batch=True,        # sort within each batch\n",
    "                                           repeat=True, # repeat the iterator for multiple epochs\n",
    "                                           device=device)\n",
    "val_iter = torchtext.data.BucketIterator(val,\n",
    "                                         batch_size=32,\n",
    "                                         sort_key=lambda x: len(x.text), # to minimize padding\n",
    "                                         sort_within_batch=True,        # sort within each batch\n",
    "                                         repeat=True, # repeat the iterator for multiple epochs\n",
    "                                         device=device)\n",
    "test_iter = torchtext.data.BucketIterator(test,\n",
    "                                          batch_size=32,\n",
    "                                          sort_key=lambda x: len(x.text), # to minimize padding\n",
    "                                          sort_within_batch=True,        # sort within each batch\n",
    "                                          repeat=True, # repeat the iterator for multiple epochs\n",
    "                                          device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[43,  4, 10,  ..., 37, 30, 72],\n",
      "        [32, 31, 25,  ..., 44, 27, 58],\n",
      "        [32, 31, 25,  ..., 20, 78,  1],\n",
      "        ...,\n",
      "        [39, 37, 48,  ...,  3,  1,  1],\n",
      "        [44, 14,  6,  ...,  6,  1,  1],\n",
      "        [25, 44,  9,  ..., 11,  1,  1]]), tensor([132, 132, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131, 131,\n",
      "        131, 131, 131, 131, 131, 131, 131, 131, 131, 130, 130, 130, 130, 130,\n",
      "        130, 130, 130, 130]))\n",
      "tensor([0, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 0, 1, 2, 2, 0, 1, 0, 1, 2, 2, 1, 2,\n",
      "        0, 1, 2, 1, 2, 1, 1, 1])\n",
      "(tensor([[ 35,  32,   3,  ...,   4,   4,  40],\n",
      "        [ 25,  22,  10,  ...,  24,  84, 124],\n",
      "        [ 54,   3,  18,  ...,  29,  74,  80],\n",
      "        ...,\n",
      "        [ 44,   5,   8,  ...,   6,  11,   1],\n",
      "        [ 44,  10,   3,  ...,  23,  14,   1],\n",
      "        [ 54,   3,  12,  ...,  31,  45,   1]]), tensor([122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 122, 121, 121, 121,\n",
      "        121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121,\n",
      "        121, 121, 121, 121]))\n",
      "tensor([1, 1, 1, 1, 1, 1, 2, 2, 0, 1, 1, 2, 1, 1, 0, 2, 1, 2, 2, 2, 2, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iter):\n",
    "    if i >= 2:\n",
    "        break\n",
    "    print(batch.text)\n",
    "#     print(batch.text[0].shape)\n",
    "    print(batch.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Another version of preprocessing data\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "\n",
    "INPUT_PATH = \"data/train_conll_spanglish.csv\"\n",
    "MAX_TWEET = 280\n",
    "\n",
    "char_to_ind = {}\n",
    "ind_to_char = {}\n",
    "\n",
    "char_to_ind.update({\"UNK\":0})\n",
    "ind_to_char.update({0:\"UNK\"})\n",
    "\n",
    "count = 1\n",
    "\n",
    "with open(INPUT_PATH, 'r') as f:\n",
    "    for line in f:\n",
    "        for char in line.split('\\t')[1]:\n",
    "            if char.lower() not in char_to_ind:\n",
    "                char_to_ind.update({char.lower():count})\n",
    "                ind_to_char.update({count:char.lower()})\n",
    "                count += 1\n",
    "\n",
    "#print(char_to_ind)\n",
    "#print(ind_to_char)\n",
    "\n",
    "n_letters = len(char_to_ind)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 554])\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "torch.Size([2, 280, 554])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "def letterToTensor(letter, n_letters):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][char_to_ind[letter]] = 1\n",
    "    return tensor\n",
    "\n",
    "def lineToTensor(line, n_letters):\n",
    "    tensor = torch.zeros(len(line), n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][char_to_ind[letter]] = 1\n",
    "    return tensor\n",
    "\n",
    "def batchToTensor(batch, n_letters):\n",
    "    tensor = torch.zeros(len(batch),MAX_TWEET,n_letters)\n",
    "    for sentence, line in enumerate(batch):\n",
    "        for li, letter in enumerate(line):\n",
    "            tensor[sentence][li][char_to_ind[letter.lower()]] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "#print(letterToTensor('o'))\n",
    "print(lineToTensor('hello how are tou').shape)\n",
    "print(batchToTensor(['hello friend', 'linear svm is better']))\n",
    "print(batchToTensor(['hello friend', 'linear svm is better']).shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "trainpath = INPUT_PATH\n",
    "train = pd.read_csv(trainpath, sep='\\\\t', names=[\"ID\",\"SENTENCE\",\"LABEL\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so that means tomorrow cruda segura lol\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(train['SENTENCE'][0].lower())\n",
    "train_char_features = batchToTensor(train['SENTENCE'], n_letters)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15000, 280, 554])\n",
      "torch.Size([280, 554])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(train_char_features.shape)\n",
    "for in_tensor in train_char_features:\n",
    "    print(in_tensor.shape)\n",
    "    break\n",
    "# train_char_features[0].shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    TextCNN implementation based on\n",
    "    https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        # first convolutional layer (three layers)\n",
    "        self.conv_0 = nn.ModuleList([\n",
    "                nn.Conv2d(in_channels = 1,\n",
    "                          out_channels = n_filters,\n",
    "                          kernel_size = (fs, embed_dim))\n",
    "                for fs in filter_sizes\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        # text = (tensor of input, tensor of input length)\n",
    "#         print(text[0].shape)\n",
    "        # convert input to embeddings\n",
    "        in_data = text[0]\n",
    "        # in_data = [batch_size, sentence_length]\n",
    "        embedded = self.embedding(in_data)\n",
    "        # embedded = [batch_size, sentence_length, embedding_dimension]\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        # embedded = [batch_size, 1, sentence_length, embedding_dimension]\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.conv_0]\n",
    "        # conved_n = [batch_size, n_filters, sentence_length - filter_size[n] - 1]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        # pooled_n = [batch_size, n_filters]\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "        # cat = [batch_size, n_filters * len(filter_sizes)]\n",
    "        logit = self.fc(cat)\n",
    "        \n",
    "        return logit\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_char_features = [num_of_tweets, max. length of each tweet, embedding_size]\n",
    "\"\"\"\n",
    "num_features = list(train_char_features.shape)\n",
    "print(num_features)\n",
    "max_tweet_length = num_features[1]\n",
    "embedding_dim = num_features[2] # vocab_size\n",
    "\"\"\"\n",
    "input_dim = embedding_dim = len(text_field.vocab)\n",
    "n_filters = 3 # number of filters\n",
    "filter_sizes = [3, 4, 5] # like character 3-gram, 4-gram, 5-gram\n",
    "output_dim = 3\n",
    "dropout = 0.5\n",
    "\n",
    "model = TextCNN(input_dim, embedding_dim, n_filters, filter_sizes, output_dim, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 368,164 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# checking the parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(logits, labels):\n",
    "    correct, total = 0, 0\n",
    "    _, predicted = torch.max(logits, 1)\n",
    "#     print(predicted, labels)\n",
    "#     print(predicted.shape, labels.shape)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "#         print(predictions, predictions.shape)\n",
    "#         print(batch.label, batch.label.shape)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = get_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = get_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 79])\n",
      "torch.Size([32, 77])\n",
      "torch.Size([32, 134])\n",
      "torch.Size([32, 106])\n",
      "torch.Size([32, 28])\n",
      "torch.Size([32, 26])\n",
      "torch.Size([32, 89])\n",
      "torch.Size([32, 58])\n",
      "torch.Size([32, 52])\n",
      "torch.Size([32, 67])\n",
      "torch.Size([32, 82])\n",
      "torch.Size([32, 120])\n",
      "torch.Size([32, 139])\n",
      "torch.Size([32, 121])\n",
      "torch.Size([32, 83])\n",
      "torch.Size([32, 93])\n",
      "torch.Size([32, 33])\n",
      "torch.Size([32, 39])\n",
      "torch.Size([32, 112])\n",
      "torch.Size([32, 43])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 75])\n",
      "torch.Size([32, 110])\n",
      "torch.Size([32, 107])\n",
      "torch.Size([32, 66])\n",
      "torch.Size([32, 57])\n",
      "torch.Size([32, 53])\n",
      "torch.Size([32, 44])\n",
      "torch.Size([32, 50])\n",
      "torch.Size([32, 80])\n",
      "torch.Size([32, 55])\n",
      "torch.Size([32, 36])\n",
      "torch.Size([32, 87])\n",
      "torch.Size([32, 113])\n",
      "torch.Size([32, 123])\n",
      "torch.Size([32, 40])\n",
      "torch.Size([32, 71])\n",
      "torch.Size([32, 46])\n",
      "torch.Size([32, 129])\n",
      "torch.Size([32, 53])\n",
      "torch.Size([32, 136])\n",
      "torch.Size([32, 65])\n",
      "torch.Size([32, 70])\n",
      "torch.Size([32, 133])\n",
      "torch.Size([32, 97])\n",
      "torch.Size([32, 47])\n",
      "torch.Size([32, 102])\n",
      "torch.Size([32, 62])\n",
      "torch.Size([32, 95])\n",
      "torch.Size([32, 38])\n",
      "torch.Size([32, 45])\n",
      "torch.Size([32, 124])\n",
      "torch.Size([32, 131])\n",
      "torch.Size([32, 17])\n",
      "torch.Size([32, 54])\n",
      "torch.Size([32, 119])\n",
      "torch.Size([32, 62])\n",
      "torch.Size([32, 118])\n",
      "torch.Size([32, 86])\n",
      "torch.Size([32, 98])\n",
      "torch.Size([32, 139])\n",
      "torch.Size([32, 81])\n",
      "torch.Size([32, 42])\n",
      "torch.Size([32, 51])\n",
      "torch.Size([32, 63])\n",
      "torch.Size([32, 103])\n",
      "torch.Size([32, 60])\n",
      "torch.Size([32, 138])\n",
      "torch.Size([32, 137])\n",
      "torch.Size([32, 49])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 109])\n",
      "torch.Size([32, 92])\n",
      "torch.Size([32, 126])\n",
      "torch.Size([32, 115])\n",
      "torch.Size([32, 88])\n",
      "torch.Size([32, 105])\n",
      "torch.Size([32, 99])\n",
      "torch.Size([32, 132])\n",
      "torch.Size([32, 73])\n",
      "torch.Size([32, 130])\n",
      "torch.Size([32, 69])\n",
      "torch.Size([32, 21])\n",
      "torch.Size([32, 136])\n",
      "torch.Size([32, 23])\n",
      "torch.Size([32, 61])\n",
      "torch.Size([32, 114])\n",
      "torch.Size([32, 117])\n",
      "torch.Size([32, 135])\n",
      "torch.Size([32, 34])\n",
      "torch.Size([32, 72])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 85])\n",
      "torch.Size([32, 143])\n",
      "torch.Size([32, 37])\n",
      "torch.Size([32, 76])\n",
      "torch.Size([32, 91])\n",
      "torch.Size([32, 59])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 125])\n",
      "torch.Size([32, 77])\n",
      "torch.Size([32, 126])\n",
      "torch.Size([32, 114])\n",
      "torch.Size([32, 56])\n",
      "torch.Size([32, 49])\n",
      "torch.Size([32, 93])\n",
      "torch.Size([32, 73])\n",
      "torch.Size([32, 60])\n",
      "torch.Size([32, 133])\n",
      "torch.Size([32, 65])\n",
      "torch.Size([32, 29])\n",
      "torch.Size([32, 36])\n",
      "torch.Size([32, 55])\n",
      "torch.Size([32, 33])\n",
      "torch.Size([32, 51])\n",
      "torch.Size([32, 57])\n",
      "torch.Size([32, 139])\n",
      "torch.Size([32, 59])\n",
      "torch.Size([32, 82])\n",
      "torch.Size([32, 53])\n",
      "torch.Size([32, 69])\n",
      "torch.Size([32, 42])\n",
      "torch.Size([32, 88])\n",
      "torch.Size([32, 22])\n",
      "torch.Size([32, 135])\n",
      "torch.Size([32, 92])\n",
      "torch.Size([32, 51])\n",
      "torch.Size([32, 30])\n",
      "torch.Size([32, 63])\n",
      "torch.Size([32, 137])\n",
      "torch.Size([32, 133])\n",
      "torch.Size([32, 115])\n",
      "torch.Size([32, 61])\n",
      "torch.Size([32, 67])\n",
      "torch.Size([32, 46])\n",
      "torch.Size([32, 40])\n",
      "torch.Size([32, 39])\n",
      "torch.Size([32, 144])\n",
      "torch.Size([32, 134])\n",
      "torch.Size([32, 47])\n",
      "torch.Size([32, 119])\n",
      "torch.Size([32, 98])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 25])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 120])\n",
      "torch.Size([32, 113])\n",
      "torch.Size([32, 108])\n",
      "torch.Size([32, 139])\n",
      "torch.Size([32, 71])\n",
      "torch.Size([32, 111])\n",
      "torch.Size([32, 99])\n",
      "torch.Size([32, 45])\n",
      "torch.Size([32, 122])\n",
      "torch.Size([32, 79])\n",
      "torch.Size([32, 48])\n",
      "torch.Size([32, 32])\n",
      "torch.Size([32, 37])\n",
      "torch.Size([32, 44])\n",
      "torch.Size([32, 105])\n",
      "torch.Size([32, 136])\n",
      "torch.Size([32, 129])\n",
      "torch.Size([32, 70])\n",
      "torch.Size([32, 76])\n",
      "torch.Size([32, 94])\n",
      "torch.Size([32, 121])\n",
      "torch.Size([32, 112])\n",
      "torch.Size([32, 27])\n",
      "torch.Size([32, 19])\n",
      "torch.Size([32, 116])\n",
      "torch.Size([32, 131])\n",
      "torch.Size([32, 35])\n",
      "torch.Size([32, 83])\n",
      "torch.Size([32, 85])\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iter, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
