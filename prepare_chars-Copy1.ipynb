{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "\n",
    "#INPUT_PATH = \"data/train_conll_spanglish.csv\"\n",
    "INPUT_PATH = \"data/train_conll_hinglish.csv\"\n",
    "MAX_TWEET = 280\n",
    "\n",
    "char_to_ind = {}\n",
    "ind_to_char = {}\n",
    "\n",
    "char_to_ind.update({\"UNK\":0})\n",
    "ind_to_char.update({0:\"UNK\"})\n",
    "\n",
    "count = 1\n",
    "\n",
    "with open(INPUT_PATH, 'r') as f:\n",
    "    for line in f:\n",
    "        for char in line.split('\\t')[1]:\n",
    "            if char.lower() not in char_to_ind:\n",
    "                char_to_ind.update({char.lower():count})\n",
    "                ind_to_char.update({count:char.lower()})\n",
    "                count += 1\n",
    "\n",
    "#print(char_to_ind)\n",
    "#print(ind_to_char)\n",
    "\n",
    "n_letters = len(char_to_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 898])\n"
     ]
    }
   ],
   "source": [
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][char_to_ind[letter]] = 1\n",
    "    return tensor\n",
    "\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][char_to_ind[letter]] = 1\n",
    "    return tensor\n",
    "\n",
    "#def tensorToLine(tensor):\n",
    "#    ind_to_char[ind=position of the 1 in the tensor] = character\n",
    "#    append character to the input line character\n",
    "\n",
    "def batchToTensor(batch):\n",
    "    tensor = torch.zeros(len(batch),MAX_TWEET,n_letters)\n",
    "    for sentence, line in enumerate(batch):\n",
    "        for li, letter in enumerate(line):\n",
    "            tensor[sentence][li][char_to_ind[letter.lower()]] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "#print(letterToTensor('o'))\n",
    "print(lineToTensor('hello how are tou').shape)\n",
    "#print(batchToTensor(['hello friend', 'linear svm is better']))\n",
    "#print(batchToTensor(['hello friend', 'linear svm is better']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nehajoshi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "trainpath = os.path.join(\"data\", \"train_conll_hinglish.csv\")\n",
    "train = pd.read_csv(trainpath, sep='\\\\t', names=[\"ID\",\"SENTENCE\",\"LABEL\"])\n",
    "test = pd.read_csv(\"sample_test.csv\", names=[\"ID\", \"SENTENCE\", \"LABEL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ adilnisarbutt pakistan ka ghra tauq he pakistan israel ko tasleem nahein kerta isko palestine kehta he- occupied palestine\n"
     ]
    }
   ],
   "source": [
    "print(train['SENTENCE'][0].lower())\n",
    "train_char_features = torch.sum(batchToTensor(train['SENTENCE']),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nehajoshi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "char_features = train_char_features\n",
    "char_features = pd.DataFrame(char_features)\n",
    "labels = pd.Series.as_matrix(train.LABEL)\n",
    "#torch.tensor(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "model_NB = MultinomialNB()\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf, sent_train, sent_test = train_test_split(char_features, labels, train['SENTENCE'], train_size=0.8)\n",
    "# X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(char_features, train.LABEL, train_size=0.75)\n",
    "model_NB.fit(X_train_tfidf, y_train_tfidf)\n",
    "predictions_tfidf = model_NB.predict(X_test_tfidf)\n",
    "accuracy_tfidf = accuracy_score(y_test_tfidf, predictions_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NB] accuracy: 0.4757185332011893, f1-score: 0.472872604189309, precision: 0.4826296920488485, recall: 0.4912570786195222\n",
      "0.4757185332011893\n",
      "2800\n",
      "Sir ghoomta hai maza ata hai rat me sapny ni aty neend achi ati hai ik dum mast- ft Kamlesh https// t co/ UhSt8pqEAo\n",
      "positive\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test_tfidf, predictions_tfidf, average='macro')\n",
    "print(\"[NB] accuracy: {}, f1-score: {}, precision: {}, recall: {}\".format(accuracy_tfidf, f1, precision, recall))\n",
    "print(accuracy_tfidf)\n",
    "print(list(sent_test.keys())[10])\n",
    "print(sent_test[list(sent_test.keys())[10]])\n",
    "print(predictions_tfidf[1])\n",
    "print(y_test_tfidf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSVM(X_train_tfidf, y_train_tfidf, X_test_tfidf, y_test_tfidf):\n",
    "    clf = SVC(kernel='linear', gamma='auto')\n",
    "    clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "    predictions_svc = clf.predict(X_test_tfidf)\n",
    "    accuracy_svc = accuracy_score(y_test_tfidf, predictions_svc)\n",
    "    # accuracy_svc\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test_tfidf, predictions_svc, average='macro')\n",
    "    print(\"[Linear SVM] accuracy: {}, f1-score: {}, precision: {}, recall: {}\".format(accuracy_svc, f1, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear SVM] accuracy: 0.49008723235527357, f1-score: 0.4926617278274259, precision: 0.49585063252840644, recall: 0.4928409160780906\n"
     ]
    }
   ],
   "source": [
    "# 'linear' shows higher accuracy than 'rbf' (default)\n",
    "clf = SVC(kernel='linear', gamma='auto')\n",
    "clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "predictions_svc = clf.predict(X_test_tfidf)\n",
    "accuracy_svc = accuracy_score(y_test_tfidf, predictions_svc)\n",
    "# accuracy_svc\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test_tfidf, predictions_svc, average='macro')\n",
    "print(\"[Linear SVM] accuracy: {}, f1-score: {}, precision: {}, recall: {}\".format(accuracy_svc, f1, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "print(predictions_svc[10])\n",
    "print(y_test_tfidf[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "X = train_char_features\n",
    "y = train.LABEL\n",
    "skf = StratifiedKFold()\n",
    "skf.get_n_splits(X, y)\n",
    "print(skf)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(\"split\")\n",
    "    trainSVM(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
